{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab8f8868-9d8d-49fc-96f8-ab37c47a27e7",
   "metadata": {},
   "source": [
    "## CPAT simulation code\n",
    "\n",
    "This Jupyter notebook contains the code needed to run the simulations included in Elliott & Buttery (2022) using `RaschPy` to produce CPAT estimates, which may then be compared with estimates from other estimation algorithms (this is not included here, but the code below saves all the response dataframes, which may be passed to other estimation algorithms as appropriate).\n",
    "\n",
    "Elliott, M. and Buttery, P. J. (2022) Non-iterative Conditional Pairwise Estimation for the Rating Scale Model, *Educational and Psychological Measurement*, *82*(5), 989-1019.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce19d0d-1597-42ba-969f-1493bec4d7c0",
   "metadata": {},
   "source": [
    "Import packages and set working directory (change this as appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ddbb2-2b9c-4af3-9408-9999c3d88f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RaschPy as rp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "os.chdir('my_working_directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19122fce-3e6c-47ee-a562-d57eceb92594",
   "metadata": {},
   "source": [
    "Set high-level experiment parameters: number of simulations, proportion of data removed for reduced and missing data sets, and priority vector methods to be compared, all as per Elliott & Buttery (2022)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebeb1b-4a2c-4067-bbb2-a63eadf2cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_sims = 10000\n",
    "missing_prop = 0.3\n",
    "methods = ['ls', 'evm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9e69e-2582-40bd-8495-4d6ded99a461",
   "metadata": {},
   "source": [
    "Set ranges for generating parameters, all as per Elliott & Buttery (2022)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be9240-d788-4fb6-aa06-0bbb35f50fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_count_range = [4, 10]\n",
    "max_score_range = [3, 7]\n",
    "item_diff_range = [0.5, 3.5]\n",
    "sample_size_log_10_range = [2, 4]\n",
    "offset_range = [-0.5, 1]\n",
    "person_sd_range = [1, 3.5]\n",
    "category_base_range = [0.5, 2]\n",
    "disorder_prob = 0.5\n",
    "max_disorder_range = [0.5, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5420e46-8f64-48db-a539-2a436fa7f5a9",
   "metadata": {},
   "source": [
    "Generate simulations and save response data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01724e7-f3c3-421b-9c03-f717bf94965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sim_parameters_df = pd.DataFrame()\n",
    "sim_dict = {}\n",
    "\n",
    "item_diffs_df = pd.DataFrame(index=[f'Item_{item + 1}' for item in range(item_count_range[1])])\n",
    "thresholds_df = pd.DataFrame(index=[threshold for threshold in range(max_score_range[1] + 1)])\n",
    "\n",
    "for sim in range(no_of_sims):\n",
    "\n",
    "    print(f'Simulation {sim + 1}/{no_of_sims}')\n",
    "\n",
    "    # Generate the generating parameters for the simulation\n",
    "\n",
    "    no_of_items = np.random.randint(item_count_range[0],\n",
    "                                    item_count_range[1] + 1)\n",
    "\n",
    "    sample_size_log_10 = np.random.uniform(sample_size_log_10_range[0],\n",
    "                                           sample_size_log_10_range[1])\n",
    "    no_of_persons = int(round(10 ** sample_size_log_10, 0))\n",
    "\n",
    "    max_score = np.random.randint(max_score_range[0],\n",
    "                                  max_score_range[1] + 1)\n",
    "\n",
    "    item_range = np.random.uniform(item_diff_range[0],\n",
    "                                   item_diff_range[1])\n",
    "\n",
    "    category_base = np.random.uniform(category_base_range[0],\n",
    "                                      category_base_range[1])\n",
    "\n",
    "    person_sd = np.random.uniform(person_sd_range[0],\n",
    "                                  person_sd_range[1])\n",
    "    \n",
    "    disorder_random = np.random.uniform(0, 1)\n",
    "    if disorder_random < disorder_prob:\n",
    "        disorder_flag = 1\n",
    "    else:\n",
    "        disorder_flag = 0\n",
    "    max_disorder = np.random.uniform(max_disorder_range[0],\n",
    "                                     max_disorder_range[1])\n",
    "    max_disorder *= disorder_flag\n",
    "    \n",
    "    offset = np.random.uniform(offset_range[0],\n",
    "                               offset_range[1])\n",
    "\n",
    "    # Add generating parameters to sim_generating_parameters_df\n",
    "\n",
    "    sim_parameters = {'no_of_items': no_of_items,\n",
    "                      'no_of_persons': no_of_persons,\n",
    "                      'max_score': max_score,\n",
    "                      'item_range': item_range,\n",
    "                      'category_base': category_base,\n",
    "                      'person_sd': person_sd,\n",
    "                      'max_disorder': max_disorder,\n",
    "                      'offset': offset}\n",
    "\n",
    "    sim_parameters_df[f'Simulation {sim + 1}'] = sim_parameters\n",
    "\n",
    "    # Generate simulation from parameters and save full data response dataframe to file\n",
    "\n",
    "    sim_dict[f'Simulation {sim + 1}'] = rp.RSM_Sim(no_of_items=no_of_items,\n",
    "                                                   no_of_persons=no_of_persons,\n",
    "                                                   max_score=max_score,\n",
    "                                                   item_range=item_range,\n",
    "                                                   category_base=category_base,\n",
    "                                                   person_sd=person_sd,\n",
    "                                                   max_disorder=max_disorder,\n",
    "                                                   offset=offset)\n",
    "\n",
    "    sim_dict[f'Simulation {sim + 1}'].scores.to_csv(f'responses_full_{sim + 1}.csv')\n",
    "\n",
    "    # Generate a reduced response dataframe (whole person lines removed), save to file\n",
    "    # and add to simulation object as a new attribute, together with reduced set of\n",
    "    # generating abilities\n",
    "\n",
    "    reduced_data = sim_dict[f'Simulation {sim + 1}'].scores.sample(frac=1-missing_prop)\n",
    "    reduced_data.to_csv(f'responses_reduced_{sim + 1}.csv')\n",
    "    sim_dict[f'Simulation {sim + 1}'].scores_reduced = reduced_data\n",
    "    \n",
    "    abils_full = sim_dict[f'Simulation {sim + 1}'].abilities\n",
    "    abils_reduced = abils_full.loc[reduced_data.index]\n",
    "    sim_dict[f'Simulation {sim + 1}'].abilities_reduced = abils_reduced\n",
    "    \n",
    "\n",
    "    # Generate a missing data response dataframe (individual responses removed MCAR)), save to file\n",
    "    # and add to simulation object as a new attribute\n",
    "\n",
    "    random_array = np.random.uniform(0, 1, (no_of_persons, no_of_items))\n",
    "    random_df = pd.DataFrame(random_array)\n",
    "    random_df.columns = sim_dict[f'Simulation {sim + 1}'].scores.columns\n",
    "    random_df.index = sim_dict[f'Simulation {sim + 1}'].scores.index\n",
    "\n",
    "    missing_data = sim_dict[f'Simulation {sim + 1}'].scores.where(random_df > missing_prop)\n",
    "\n",
    "    missing_data.to_csv(f'responses_missing_{sim + 1}.csv')\n",
    "    sim_dict[f'Simulation {sim + 1}'].scores_missing = missing_data\n",
    "    \n",
    "# Save sim_generating_parameters_df and create pickle file of dictionary all simulations;\n",
    "# the pickle file may be opened later to retrieve the simulations with the three response\n",
    "# dataframes and generating parameters stored as attributes (see cell at end).\n",
    "\n",
    "sim_parameters_df.to_csv('simulation_generating_parameters.csv')\n",
    "\n",
    "with open('simulation_dictionary.pkl', 'wb') as file:\n",
    "    pickle.dump(sim_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377d14f-578f-48ec-acfc-b9ee04d52d73",
   "metadata": {},
   "source": [
    "Define functions for RMSE, SD ratio and RMS parameter estimation residual metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846508c6-08f3-4833-bb73-bd7bbec97a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x, y):\n",
    "\n",
    "    mse = ((x - y) ** 2).mean()\n",
    "    \n",
    "    return np.sqrt(mse)\n",
    "\n",
    "def sd_ratio(x, y):\n",
    "\n",
    "    return y.std() / x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb9597-b400-48b9-ab37-6318432c6815",
   "metadata": {},
   "source": [
    "Set the additive smoothing constant for parameter estimation. Here, the experiment is only run with a single additive smoothing constant (the default `RaschPy` value of `constant=0.1`); to compare performance using different additive smoothing constants, change the value in this cell and re-run the cell below (remember to move the output files first so they aren't over-written!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd283f-1a16-4c4a-98f4-a56d8b991d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c1410a-348b-4870-84e8-85f98fba347b",
   "metadata": {},
   "source": [
    "Generate parameter estimates and save comparison metrics to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c3f2c7-f00c-4bdd-b2a2-74da2f082d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results_dict_full = {}\n",
    "rsm_dict_full = {}\n",
    "results_dict_reduced = {}\n",
    "rsm_dict_reduced = {}\n",
    "results_dict_missing = {}\n",
    "rsm_dict_missing = {}\n",
    "\n",
    "for method in methods:\n",
    "\n",
    "    results_dict_full[method] = {}\n",
    "    rsm_dict_full[method] = pd.DataFrame()\n",
    "    results_dict_reduced[method] = {}\n",
    "    rsm_dict_reduced[method] = pd.DataFrame()\n",
    "    results_dict_missing[method] = {}\n",
    "    rsm_dict_missing[method] = pd.DataFrame()\n",
    "    \n",
    "    for sim in range(no_of_sims):\n",
    "    \n",
    "        print(f'Simulation {sim + 1}/{no_of_sims}')\n",
    "    \n",
    "        # Generate estimates from the responses\n",
    "\n",
    "        # Full data set\n",
    "\n",
    "        rsm_sim = sim_dict[f'Simulation {sim + 1}']\n",
    "    \n",
    "        data_full = rsm_sim.scores\n",
    "        max_score = rsm_sim.max_score\n",
    "    \n",
    "        rsm_full = rp.RSM(data_full, max_score=max_score)\n",
    "    \n",
    "        rsm_full.calibrate(method=method, constant=constant)\n",
    "\n",
    "        diffs_rmse = rmse(rsm_sim.diffs, rsm_full.diffs)\n",
    "        diffs_sd_ratio = sd_ratio(rsm_sim.diffs, rsm_full.diffs)\n",
    "                                      \n",
    "        thresholds_rmse = rmse(rsm_sim.thresholds, rsm_full.thresholds)\n",
    "        thresholds_sd_ratio = sd_ratio(rsm_sim.thresholds, rsm_full.thresholds)\n",
    "\n",
    "        exp_score_array_estimated_full = np.array([rsm_full.exp_score(rsm_sim.abilities.loc[person],\n",
    "                                                                      rsm_full.diffs[item],\n",
    "                                                                      rsm_full.thresholds)\n",
    "                                                   for item in rsm_sim.items for person in rsm_sim.persons])\n",
    "        exp_score_array_generating_full = np.array([rsm_full.exp_score(rsm_sim.abilities.loc[person],\n",
    "                                                                       rsm_sim.diffs[item],\n",
    "                                                                       rsm_sim.thresholds)\n",
    "                                                    for item in rsm_sim.items for person in rsm_sim.persons])\n",
    "        \n",
    "        rms_param_est_residuals = rmse(exp_score_array_estimated_full,\n",
    "                                       exp_score_array_generating_full)\n",
    "\n",
    "        rsm_sim_results_full = {'RMSE diffs': diffs_rmse,\n",
    "                                'SD ratio diffs': diffs_sd_ratio,\n",
    "                                'RMSE thresholds': thresholds_rmse,\n",
    "                                'SD ratio thresholds': thresholds_sd_ratio,\n",
    "                                'RMS parameter estimation residuals': rms_param_est_residuals}\n",
    "\n",
    "        results_dict_full[method][f'Simulation {sim + 1}'] = rsm_sim_results_full\n",
    "        rsm_dict_full[method][f'Simulation {sim + 1}'] = rsm_full\n",
    "\n",
    "        # Reduced data set\n",
    "\n",
    "        data_reduced = pd.read_csv(f'responses_reduced_{sim + 1}.csv', index_col=0)\n",
    "    \n",
    "        rsm_reduced = rp.RSM(data_reduced, max_score=max_score)\n",
    "    \n",
    "        rsm_reduced.calibrate(method=method)\n",
    "\n",
    "        diffs_rmse = rmse(rsm_sim.diffs, rsm_reduced.diffs)\n",
    "        diffs_sd_ratio = sd_ratio(rsm_sim.diffs, rsm_reduced.diffs)\n",
    "                                      \n",
    "        thresholds_rmse = rmse(rsm_sim.thresholds, rsm_reduced.thresholds)\n",
    "        thresholds_sd_ratio = sd_ratio(rsm_sim.thresholds, rsm_reduced.thresholds)\n",
    "\n",
    "        exp_score_array_estimated_reduced = np.array([rsm_reduced.exp_score(rsm_sim.abilities_reduced.loc[person],\n",
    "                                                                            rsm_reduced.diffs[item],\n",
    "                                                                            rsm_reduced.thresholds)\n",
    "                                                      for item in rsm_sim.items for person in data_reduced.index])\n",
    "        exp_score_array_generating_reduced = np.array([rsm_reduced.exp_score(rsm_sim.abilities_reduced.loc[person],\n",
    "                                                                             rsm_sim.diffs[item],\n",
    "                                                                             rsm_sim.thresholds)\n",
    "                                                       for item in rsm_sim.items for person in data_reduced.index])\n",
    "        \n",
    "        rms_param_est_residuals = rmse(exp_score_array_estimated_reduced,\n",
    "                                       exp_score_array_generating_reduced)\n",
    "\n",
    "        rsm_sim_results_reduced = {'RMSE diffs': diffs_rmse,\n",
    "                                   'SD ratio diffs': diffs_sd_ratio,\n",
    "                                   'RMSE thresholds': thresholds_rmse,\n",
    "                                   'SD ratio thresholds': thresholds_sd_ratio,\n",
    "                                   'RMS parameter estimation residuals': rms_param_est_residuals}\n",
    "\n",
    "        results_dict_reduced[method][f'Simulation {sim + 1}'] = rsm_sim_results_reduced\n",
    "        rsm_dict_reduced[method][f'Simulation {sim + 1}'] = rsm_reduced\n",
    "\n",
    "        # Missing data data set\n",
    "\n",
    "        data_missing = pd.read_csv(f'responses_missing_{sim + 1}.csv', index_col=0)\n",
    "    \n",
    "        rsm_missing = rp.RSM(data_missing, max_score=max_score)\n",
    "    \n",
    "        rsm_missing.calibrate(method=method)\n",
    "\n",
    "        diffs_rmse = rmse(rsm_sim.diffs, rsm_missing.diffs)\n",
    "        diffs_sd_ratio = sd_ratio(rsm_sim.diffs, rsm_missing.diffs)\n",
    "                                      \n",
    "        thresholds_rmse = rmse(rsm_sim.thresholds, rsm_missing.thresholds)\n",
    "        thresholds_sd_ratio = sd_ratio(rsm_sim.thresholds, rsm_missing.thresholds)\n",
    "\n",
    "        exp_score_array_estimated_missing = np.array([rsm_missing.exp_score(rsm_sim.abilities.loc[person],\n",
    "                                                                            rsm_missing.diffs[item],\n",
    "                                                                            rsm_missing.thresholds)\n",
    "                                                      for item in rsm_sim.items for person in rsm_sim.persons\n",
    "                                                      if data_missing.loc[person,item] == data_missing.loc[person,item]])\n",
    "        exp_score_array_generating_missing = np.array([rsm_missing.exp_score(rsm_sim.abilities.loc[person],\n",
    "                                                                             rsm_sim.diffs[item],\n",
    "                                                                             rsm_sim.thresholds)\n",
    "                                                       for item in rsm_sim.items for person in rsm_sim.persons\n",
    "                                                       if data_missing.loc[person,item] == data_missing.loc[person,item]])\n",
    "        \n",
    "        rms_param_est_residuals = rmse(exp_score_array_estimated_missing,\n",
    "                                       exp_score_array_generating_missing)\n",
    "\n",
    "        rsm_sim_results_missing = {'RMSE diffs': diffs_rmse,\n",
    "                                   'SD ratio diffs': diffs_sd_ratio,\n",
    "                                   'RMSE thresholds': thresholds_rmse,\n",
    "                                   'SD ratio thresholds': thresholds_sd_ratio,\n",
    "                                   'RMS parameter estimation residuals': rms_param_est_residuals}\n",
    "\n",
    "        results_dict_missing[method][f'Simulation {sim + 1}'] = rsm_sim_results_missing\n",
    "        rsm_dict_missing[method][f'Simulation {sim + 1}'] = rsm_missing\n",
    "\n",
    "# Save results to file\n",
    "\n",
    "for method in methods:\n",
    "    pd.DataFrame(results_dict_full[method]).to_csv(f'results_full_{method}.csv')\n",
    "    pd.DataFrame(results_dict_reduced[method]).to_csv(f'results_reduced_{method}.csv')\n",
    "    pd.DataFrame(results_dict_missing[method]).to_csv(f'results_missing_{method}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6670c4-a1d6-43c8-a0d7-4957edfc825f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "round(pd.DataFrame(results_dict_full['evm']), 3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783f0294-47dd-48b7-ae65-187837815a92",
   "metadata": {},
   "source": [
    "### Retrieving simulations from file\n",
    "\n",
    "This cell is not part of the simulation, but contains what is needed to retrieve the simulation objects later, each of which contains all the generating parameters and three response dataframes. To open one of the simulations, `RaschPy` is needed, which is why there is a line here to import it (redundant if it has previously been imported)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec83841-a4da-4507-887d-cceb07d00a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RaschPy as rp\n",
    "with open('simulation_dictionary.pkl', 'rb') as file:\n",
    "    retrieved_sim_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb60a87-cdc3-49ee-9440-028182deff02",
   "metadata": {},
   "source": [
    "View the full response dataframe for Simulation 1 in the retrieved dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf366b1-9434-4b81-b325-145d5d8279d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_sim_dict['Simulation 1'].scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789fd42e-adc9-4a63-ba22-b3a08021e74f",
   "metadata": {},
   "source": [
    "View the full generating item difficulties for Simulation 1 in the retrieved dictionary. For the generating thresholds, replace `diffs` with `thresholds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ba435-dcc2-45fb-8679-bb9f53c2b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_sim_dict['Simulation 1'].diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dec367-fee8-46d3-a60f-ccf0428d73b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
