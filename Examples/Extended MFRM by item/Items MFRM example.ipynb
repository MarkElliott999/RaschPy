{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f8a998-9244-4153-8c8a-6fac6aca784c",
   "metadata": {},
   "source": [
    "### RaschPy vector-by-items MFRM worked example\n",
    "\n",
    "This notebook works through a sample Rasch analysis of a simulated data set (200 persons, 8 items with a maximum score of 5, all rated by 8 raters, no missing data), taking you through the relevant commands step by step, with notes before each cell. Relevant outputs will appear below each cell.\n",
    "\n",
    "Import the modules and set the working directory (here called `my_working_directory`)to where you have saved the `mfrm_items_scores.csv` file - you will also save your output files here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659d891-8766-476b-a8a5-b8d4a72aa634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RaschPy as rp\n",
    "import os\n",
    "\n",
    "os.chdir('my_working_directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30053bc1-d575-40de-8b1f-2e0d342604ee",
   "metadata": {},
   "source": [
    "Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f158f64-567f-4303-87d0-0b067f69a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, invalid_responses = rp.loadup_mfrm_single('mfrm_items_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7b10e-ad50-46f4-b2a7-18ab18636540",
   "metadata": {},
   "source": [
    "Check the data - view the first two lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6714c6-5c82-4c01-ad76-fe0fdbba377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073cab1d-493d-400b-8e31-3ea7c4970b28",
   "metadata": {},
   "source": [
    "Check for any invalid responses (not usable for estimation purposes and excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff77f7-4611-405f-9025-3bf091978338",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f0d0f-3c6b-4d33-a777-6aa700b95965",
   "metadata": {},
   "source": [
    "Create an MFRM object from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5a08f-f36a-4e5e-bbed-0613ea77ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm = rp.MFRM(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e8d66e-d31d-4273-9f05-172bd1380c47",
   "metadata": {},
   "source": [
    "Generate item estimates. The `%%time` \"magic function\" returns the time taken to run the cell contents (algorithm run time in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56818da9-6ddd-477d-a7a0-753a62af5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mfrm.calibrate_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae550998-02a7-4a20-9408-4f9e5bbaa4ca",
   "metadata": {},
   "source": [
    "Check the item difficult estimates - view the first two items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f3b93-bb2d-4cee-9083-5a7610eba3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.diffs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283fdcda-2942-4707-b06d-77b56ff47825",
   "metadata": {},
   "source": [
    "Generate a table of item statistics (and check run time), and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297335b7-ef01-4544-b010-f321c7b35008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mfrm.item_stats_df_items()\n",
    "mfrm.item_stats_items.to_csv('mfrm_items_item_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8d310-edd1-4e7e-99e6-872f39cf6fe4",
   "metadata": {},
   "source": [
    "Check the item statistics table - view the first two items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922dffad-bf67-42cf-a1a6-6c78bc19ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.item_stats_items.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd59ea-3839-4457-bcbc-7c03abaec2be",
   "metadata": {},
   "source": [
    "Generate a table of threshold statistics (and check run time), and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a3c31-2e14-48f0-a618-8ffd453d2875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mfrm.threshold_stats_df_items()\n",
    "mfrm.threshold_stats_items.to_csv('mfrm_items_threshold_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc154fa5-c982-4ce5-9b2d-4a7aff264d90",
   "metadata": {},
   "source": [
    "Check the threshold statistics table - view the first two thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d174ee59-ede4-437a-aa0f-b4952e5b885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.threshold_stats_items.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19bfd7-0a05-4307-82d2-8b45cafbad68",
   "metadata": {},
   "source": [
    "Generate a table of rater statistics (and check run time), and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9268b58-c382-4b41-9018-7bf0dcc8eb35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mfrm.rater_stats_df_items()\n",
    "mfrm.rater_stats_items.to_csv('mfrm_items_rater_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf23b87-ba20-434c-a881-4c95ba829965",
   "metadata": {},
   "source": [
    "Check the rater statistics table - view the first two raters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36d023-5994-4e4e-a097-0ba9cc9910c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.rater_stats_items.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1b2a2-1336-48c7-ae66-b0d21da0aa2d",
   "metadata": {},
   "source": [
    "Generate a table of person statistics (and check run time), and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c50ee-6757-40eb-857b-4af6fcc9e4e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mfrm.person_stats_df_items()\n",
    "mfrm.person_stats_items.to_csv('mfrm_items_person_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc00bc19-76a9-4c14-9814-4d67f186d0fb",
   "metadata": {},
   "source": [
    "Check the person statistics table - view the first two items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cafb8f-a1d3-4761-a547-6c5a11ba5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.person_stats_items.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e54dbb-1f51-4701-a8f0-0774e92e560a",
   "metadata": {},
   "source": [
    "Generate a table of test-level statistics (and check run time), and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9512c67-d96e-4ae3-b9cc-725638347f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mfrm.test_stats_df_items()\n",
    "mfrm.test_stats_items.to_csv('mfrm_items_test_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62d1c2-6fa7-458d-aa0f-f8514fdea41a",
   "metadata": {},
   "source": [
    "Check the test statistics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0887e-9fb6-44fc-8af2-188d52159523",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.test_stats_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472a2001-443f-43f4-bef6-381faeb25da6",
   "metadata": {},
   "source": [
    "Run a residual correlation analysis for items (and check run time), and save relevant output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddbe592-9eee-4e05-b918-6b6e3819cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mfrm.item_res_corr_analysis_items()\n",
    "mfrm.item_residual_correlations_items.to_csv('mfrm_items_item_residual_correlations.csv')\n",
    "mfrm.item_loadings_items.to_csv('mfrm_items_item_loadings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74f5db-6b5b-4bc4-a196-e70d6e84feec",
   "metadata": {},
   "source": [
    "View the table of pairwise standard residual correlations (pairwise local item independence check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60634d-7e4e-41d6-af0f-bf0c8c1c8661",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.item_residual_correlations_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2340bea1-e446-480b-b2af-37a90fb95a26",
   "metadata": {},
   "source": [
    "View the item loadings on the first principal component of the pairwise standard residual correlations (dimensionality test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f51f26-248e-4419-845a-a4f83228f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.item_loadings_items['PC 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0658cda7-dd41-4bd8-a996-a7a1af464215",
   "metadata": {},
   "source": [
    "Run a residual correlation analysis for raters (and check run time), and save relevant output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d4015-c027-49e2-81e2-72fe3ad5d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mfrm.rater_res_corr_analysis_items()\n",
    "mfrm.rater_residual_correlations_items.to_csv('mfrm_items_rater_residual_correlations.csv')\n",
    "mfrm.rater_loadings_items.to_csv('mfrm_items_rater_loadings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1bfee-fddf-4833-8965-223230d7c42a",
   "metadata": {},
   "source": [
    "View the table of pairwise standard residual correlations (pairwise local rater independence check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b73d0-3d8b-4fd0-9366-c3505d074e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.rater_residual_correlations_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b38d19-e257-4cfd-9b23-6cba3d0d5334",
   "metadata": {},
   "source": [
    "View the rater loadings on the first principal component of the pairwise standard residual correlations (dimensionality test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bdb999-6a90-492c-bc53-e8db5f7017e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.rater_loadings_items['PC 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4951d33a-4b3b-4749-a91b-dbfc7584963f",
   "metadata": {},
   "source": [
    "Produce an item characteristic curve (item response function) curve for Item 2, with oberved category means plotted and the threshold (item difficulty) marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16849fd7-8757-42f0-8474-2a89ed32e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.icc_items('Item_2', title='ICC for Item 2', obs=True, central_diff=True, cat_highlight=3, xmin=-7, xmax=7, filename='my_items_mfrm_icc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf9b4f-9352-4c84-886c-2bdf3f48d1e7",
   "metadata": {},
   "source": [
    "Produce a set of category response curves for Item 2, with category 1 highlighted and the thresholds marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff03fd0-61b4-41ac-a891-fd0975809781",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.crcs_items('Item_2', thresh_lines=True, cat_highlight=1, xmin=-7, xmax=7, filename='my_items_mfrm_crcs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5cb85-9186-4fe2-8ab9-b25fcf7962bf",
   "metadata": {},
   "source": [
    "Produce a set of threshold characteristic curves for Item 2, with oberved category means plotted for threshold 3, category 1 highlighted and the thresholds marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e459eca-1458-4f46-a33b-3d163860ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.threshold_ccs_items('Item_2', thresh_lines=True, obs=[3], cat_highlight=1, xmin=-7, xmax=7, filename='my_items_mfrm_threshold_ccs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce7ef26-43b7-4064-a52d-4d5d8fc230c6",
   "metadata": {},
   "source": [
    "Produce an item information function curve for Item 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7532a6-047d-45e0-978c-0278e78dadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.iic_items('Item_2', title='Information for Item 2', xmin=-7, xmax=7, filename='my_items_mfrm_iic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfcf073-25c5-4ff3-b7c6-888cabc71a2f",
   "metadata": {},
   "source": [
    "Produce a test characteristic curve (test response function), with abilities corresponding to scores of 20 and 30 plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ea5f1d-db2f-40d9-a8f3-b248ca6f3f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.tcc_items(score_lines=[20, 30], score_labels=True, xmin=-7, xmax=7, filename='my_items_mfrm_tcc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7826f917-eac5-4ce9-9592-c3c2899d634a",
   "metadata": {},
   "source": [
    "Produce a test information curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20303e0-b4e8-4288-86c6-cfe90ebc78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.test_info_items(xmin=-7, xmax=7, filename='my_items_mfrm_test_info_curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6737af02-9cb4-4055-bad8-f14cc2823cf8",
   "metadata": {},
   "source": [
    "Produce a test CSEM (conditional standard error of measurement) curve, with the CSEM corresponding to an ability of -3 plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881b7ca-dc6a-40c1-a8ed-783048c9ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.test_csem_items(point_csem_lines=[-3], point_csem_labels=True, ymax=1.4, xmin=-7, xmax=7, filename='my_items_mfrm_csem_curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de30e8c-b457-4867-9947-2f973f662569",
   "metadata": {},
   "source": [
    "Produce a histogram of standardised residuals, with a normal distribution curve overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff3fd5-9783-4318-a36f-d57e6ce4f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.std_residuals_plot_items(bin_width=0.6, normal=True, filename='my_items_mfrm_std_residuals_plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4727b3-c548-474d-9561-33ba7c02b807",
   "metadata": {},
   "source": [
    "Now run an anchored analysis. First, anchor the analysis to Raters 1-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eeb7b1-78a9-4130-b131-ee1678f82fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mfrm.calibrate_items_anchor(anchor_raters=['Rater_1', 'Rater_2', 'Rater_3', 'Rater_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a296648-10b6-4eea-b560-db32d206712a",
   "metadata": {},
   "source": [
    "Check the anchored item difficulties against the unanchored difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b42f66f-75af-4269-94f3-89b9d5e97648",
   "metadata": {},
   "source": [
    "mfrm.diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a568a-beea-4eb7-90cd-1d96a75d35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrm.anchor_diffs_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff1ae4-eb49-4ff1-b0a9-d470cfe8653d",
   "metadata": {},
   "source": [
    "Check the anchored severities against the unanchored ones (using the pandas package to turn the dictionary into a nice tidy dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ba4ed-bccb-46f2-bd9c-8e46dfd45718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(mfrm.severities_items).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9314f3bc-3984-4bce-bcff-c2ec7cb5934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mfrm.anchor_severities_items).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87abcdb1-b2d9-4257-bb6d-5f6c95cd54c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
